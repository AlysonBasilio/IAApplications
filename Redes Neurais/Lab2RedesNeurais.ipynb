{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2º Laboratório CTC-17: Redes Neurais\n",
    "## INSTITUTO TECNOLÓGICO DE AERONÁUTICA\n",
    "### Professor: Tasinaffo\n",
    "### Alunos: Alyson Basílio e Antonio Matos\n",
    "### São José dos Campos, 29/11/2017\n",
    "\n",
    "## Introdução\n",
    "\n",
    "A Figura 01 ilustra a arquitetura de uma rede neural Multilayer Perceptron (rede MLP) com uma camada interna não linear e uma camada de saída linear. Pode ser demonstrado matematicamente que tal arquitetura de rede é um aproximador universal de funções.\n",
    "\n",
    "![Figura 01](Figura01.png)\n",
    "\n",
    "A Figura 02 exibe graficamente como é utilizada a metodologia NARMAX para representar a dinâmica de uma planta do mundo real. A planta pode ser qualquer sistema que tenha comportamento parecido com sistemas dinâmicos que podem ser regidos por equações diferencias ordinárias. Exemplos de uma planta seriam: funcionamento da bolsa de valores, movimentos de atitude de satélites que devem ser controlados de forma autônoma em órbitas ao redor da terra e a dinâmica da variação de vazões de rios no recorrer das estações do ano. Observando a Figura 02 percebe-se que através de um aprendizado supervisionado a rede neural é treinada para aprender o comportamento real da planta dentro de um erro aceitável. Teoricamente, isso será sempre possível através de uma rede MLP ou RBF, pois demonstra-se matematicamente que tais redes neurais são aproximadores universais de funções.\n",
    "\n",
    "![Figura 02](Figura02.png)\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Nesta proposta de laboratório deverá ser montada uma arquitetura de rede MLP como esquematizado na Figura 03. A rede deverá ter quatro entradas e duas saídas. As primeiras duas entradas deverão estar associadas aos valores da vazão do primeiro rio, as duas seguintes às razões do segundo rio. Observe que cada rio possuirá duas entradas atrasadas.\n",
    "\n",
    "![Figura 03](Figura03.png)\n",
    "\n",
    "A proposta deste laboratório é resolver o problema de predição de vazão de rios utilizando a metodologia NARMAX projetada com uma arquitetura de rede neural do tipo Multilayer Perceptron.\n",
    "\n",
    "## Laboratório\n",
    "\n",
    "O trabalho para o planejamento do projeto de uma rede neural artificial possui sete passos primários: 1. Coleta de dados, 2. Criação da Rede Neural, 3. Configuração da Rede Neural, 4.Inicialização dos pesos e bias, 5. Treinamento da Rede Neural, 6. Validação e Teste da Rede Neural e 7. Utilização da Rede Neural.\n",
    "\n",
    "## 1. Coleta de dados\n",
    "\n",
    "Os dados estão em dois arquivos: _Rio 01 Camargos.txt_ e _Rio 02 Furnas.txt_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 984)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"Rio 01 Camargos.txt\", \"r\")\n",
    "data = file.read()\n",
    "river1_temp = data.split(\"\\n\")\n",
    "river1 = []\n",
    "for ano in river1_temp:\n",
    "    river1 += ano.split('\\t')\n",
    "file.close()\n",
    "\n",
    "file = open(\"Rio 02 Furnas.txt\", \"r\")\n",
    "data = file.read()\n",
    "river2_temp = data.split(\"\\n\")\n",
    "river2 = []\n",
    "for ano in river2_temp:\n",
    "    river2 += ano.split('\\t')\n",
    "file.close()\n",
    "\n",
    "len(river1), len(river2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode-se observar, há dados de vazão de 984 meses para cada rio, o que corresponde a 82 anos.\n",
    "Após a coleta de dados, três procedimentos de pré-processamento são conduzidos para treinar uma RNA de uma maneira mais eficiente. Esses procedimentos são: (1) resolver o problema de perda de dados, (2) normalização dos dados (em geral entre 0 e 1 ou entre -1 e 1) e (3) baralhamento aleatório dos dados. Em geral, os dados perdidos são substituídos pela média\n",
    "dos vizinhos mais próximos. Isto não será feito, pois levaremos em consideração que os dados estão completos. O procedimento de normalização realizado antes de apresentar os dados de entrada para a rede é geralmente uma boa prática, uma vez que misturar variáveis com grandes magnitudes e pequenas magnitudes confundirá os algoritmos de treinamento que terão dificuldade de aprender as variáveis com magnitudes pequenas. Contudo, isso não será necessário pois os dados estão na mesma magnitude.\n",
    "Deve-se, então, dividir os dados para treinamento, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {'r1':river1[:984-24], 'r2':river2[:984-24]}\n",
    "validation_data = {'r1':river1[984-24:984-12], 'r2':river2[984-24:984-12]}\n",
    "test_data = {'r1':river1[984-12:], 'r2':river2[984-12:]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizou-se, portanto, o penúltimo ano para validação e o último ano para teste.\n",
    "\n",
    "## Criação da Rede\n",
    "\n",
    "Neste estágio, o projetista da rede especifica o número de camadas internas, o número de neurônios em cada camada, a função de transferência em cada camada (ver Figura 04) e a função de performance. As funções de transferências mais comuns utilizadas no projeto de redes neurais são (ver Figura 04): função linear, sigmoides (tangente hiperbólica e logística) e gaussianas.\n",
    "\n",
    "![Figura 04](Figura 04.png)\n",
    "<p style=\"text-align: center;\">  **Figura 04: Exemplos de funções de Construção Interna** </p>\n",
    "\n",
    "Agora vamos importar a biblioteca que contém a estrutura de uma rede neural MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
